# 综述

简单描述了一下动作识别的发展（主要是一些深度学习模型），没有具体的原理，大致是“动作识别近现代史”。

（文献：Zhu Y, Li X, Liu C, et al. A comprehensive study of deep video action recognition[J]. arXiv preprint arXiv: 2012.06567, 2020.）

## 第一部分：总论

1. 人类行为分析是视频分析中重要的一部分。

2. 动作识别的难点：

   （1）时间信息的表征：有些动作可以直接通过画面确定，但有些需要结合时间信息（上下文）。

   （2）组内差异和组间差异都很大：视角变化会引起组内差异。

   （3）计算成本高。

   （4）不同模型的评估方法不同，难以对比性能。

## 第二部分：“原始”阶段

1. IDT：一种很好的手工特征（使用手工特征+传统机器学习）。

   （文献：Wang H, Schmid C. Action recognition with improved trajectories[C]. Proceedings of the IEEE international conference on computer vision, 2013: 3551-3558.）

2. DeepVideo：早期使用深度学习的尝试，逐帧卷积+融合，效果不如IDT。

   （文献：Karpathy A, Toderici G, Shetty S, et al. Large-scale video classification with convolutional neural networks[C]. Proceedings of the IEEE conference on computer vision and pattern recognition, 2014: 1725-1732.）

## 第三部分：聚合时间信息的第一种手段——双流网络

1. 双流网络的基本思想：分别处理时间信息和空间信息+聚合。

   （文献：Simonyan K, Zisserman A. Two-stream convolutional networks for action recognition in videos[J]. Advances in neural information processing systems, 2014, 27.）

2. 光流：描述图中的有效运动部分。H\*W\*L的视频可以提取H\*W\*2L的光流。

   （文献：Horn B K P, Schunck B G. Determining optical flow[J]. Artificial intelligence, 1981, 17(1-3): 185-203.）

3. 融合策略：

   （1）late fusion：在最后作加权平均。

   （2）early fusion：在2D卷积后进行聚合（sum/max/bilinear/conv/concate）。

   （文献：Feichtenhofer C, Pinz A, Zisserman A. Convolutional two-stream network fusion for video action recognition[C]. Proceedings of the IEEE conference on computer vision and pattern recognition, 2016: 1933-1941.）

4. 深层双流网络在小数据集上克服过拟合的方法：

   （1）跨模态初始化（cross-modality initialization）。

   （2）同步批次标准化（synchronized batch initialization）。

   （3）基于角裁剪和多尺度裁剪的数据增强  （corner cropping and multi-scale cropping data augmentation）。

   （4）大dropout率（large dropout ratio）。

   （文献：Wang L, Xiong Y, Wang Z, et al. Towards good practices for very deep two-stream convnets[J]. arXiv preprint arXiv: 1507.02159, 2015.）

5. MotionNet：无监督地学习运动信息（替代双流网络中的光流）。

   （文献：Zhu Y, Lan Z, Newsam S, et al. Hidden two-stream convolutional networks for action recognition[C]. Asian conference on computer vision. Springer, Cham, 2018: 363-378.）

## 第四部分：聚合时间信息的另一种手段——3D卷积

1. 3D卷积的含义：两个时间维度+一个空间维度。

   （文献：Ji S, Xu W, Yang M, et al. 3D convolutional neural networks for human action recognition[J]. IEEE transactions on pattern analysis and machine intelligence, 2012, 35(1): 221-231.）

2. C3D：实际应用中的3D卷积模型，耗时且标准性能不佳但泛化能力较强，常用作特征提取器。

   （文献：Tran D, Bourdev L, Fergus R, et al. Learning spatiotemporal features with 3d convolutional networks[C]. Proceedings of the IEEE international conference on computer vision. 2015: 4489-4497.）

3. I3D：I：Inflate，膨胀。使用“初始化光流”，将在ImageNet上训练的2D模型权重重映射到3D，克服训练困难的问题。

   （文献：Carreira J, Zisserman A. Quo vadis, action recognition? a new model and the kinetics dataset[C]. Proceedings of the IEEE conference on computer vision and pattern recognition, 2017: 6299-6308.）

4. 长程聚合：3D卷积存在只能聚合到卷积核覆盖的短时信息的问题，需要通过某种手段进行长程聚合。常见方法包含：

   （1）Non-local：残差聚合。

   （文献：Wang X, Girshick R, Gupta A, et al. Non-local neural networks[C]. Proceedings of the IEEE conference on computer vision and pattern recognition, 2018: 7794-7803.）

   （2）4D CNN：视频级卷积。

   （文献：Zhang S, Guo S, Huang W, et al. V4d: 4d convolutional neural networks for video-level representation learning[J]. arXiv preprint arXiv: 2002.07442, 2020.）

5. 通道可分离卷积： 高效的3D卷积。

   （文献：Kopuklu O, Kose N, Gunduz A, et al. Resource efficient 3d convolutional neural networks[C]. Proceedings of the IEEE/CVF international conference on computer vision workshops, 2019: 0-0.）

6. Slow-Fast：快速路径（fast pathway，低帧率下的语义信息）和慢速路径（slow pathway，高帧率下的运动信息）。

   （文献：Feichtenhofer C, Fan H, Malik J, et al. Slowfast networks for video recognition[C]. Proceedings of the IEEE/CVF international conference on computer vision, 2019: 6202-6211.）

7. X3D：更多的可调节参数（空间分辨率等）。

   （文献：Feichtenhofer C. X3d: Expanding architectures for efficient video recognition[C]. Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition, 2020: 203-213.）

## 第五部分：其他模型

1. LRCN：使用LSTM聚合时间信息。

   （文献：Donahue J, Anne Hendricks L, Guadarrama S, et al. Long-term recurrent convolutional networks for visual recognition and description[C]. Proceedings of the IEEE conference on computer vision and pattern recognition, 2015: 2625-2634.）

2. TSN：基于段（segment）的方法+片段共识（segmental consensus）。

   （文献：Wang L, Xiong Y, Wang Z, et al. Temporal segment networks: Towards good practices for deep action recognition[C]. European conference on computer vision, Springer, Cham, 2016: 20-36.）

3. 多流网络（Multi-stream networks）：更多模态（pose/object/audio/depth）。

   （文献：Chéron G, Laptev I, Schmid C. P-cnn: Pose-based cnn features for action recognition[C]. Proceedings of the IEEE international conference on computer vision. 2015: 3218-3226.）

## 第六部分：模型缺陷

1. 双流网络的缺陷：需要预计算光流。
2. 3D卷积：训练时间长，应用不满足实时性，不支持非GPU设备。

## 第七部分：数据集

1. 公认的模型评价标准：Kinetics系列、Sth-Sth系列。

2. 数据集构建：

   （1）定义动作列表（action list）。

   （2）分析视频所含动作。

   （3）记录动作的开始时间和结束时间。

   （4）去除重复样本和噪声样本。

3. 数据集构建中的难点：

   （1）行为的抽象性。

   （2）开始时间和结束时间模糊。

   （3）引用的数据集只有链接。