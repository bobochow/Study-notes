# 双流网络

这周主要任务是“考古”。追溯到了1973年心理学家约翰逊对于人类感知生物运动中的视觉感知进行的移动光照显示器（MLD）实验，但感觉跟我们的联系不大，所以最终选择了这篇“开山之作”双流网络。

（文献：Simonyan K, Zisserman A. Two-stream convolutional networks for action recognition in videos[J]. Advances in neural information processing systems, 2014, 27.）

1. 文章信息：2014年NIPS，视频分析的开山之作，首个将深度学习模型较为成功的应用到视频分析中的案例，作者是牛津大学VGG组的Karen和Andrew（提VGGNet的二人）。

2. 在双流网络之前遇到的问题：简单的将深度学习生搬硬套到动作识别上效果不佳。2014年CVPR（比它早，CVPR夏天开，NIPS冬天开）上的DeepVideo进行了丰富的实验并构建了一个包含一百万个样本的Sports1M。但最终准确率比IDT低20%。

3. 分析原因：CNN可以学习局部特征却不擅长学习运动规律。

4. 引入光流：人为提取光流作为运动信息。

5. 文章贡献：

   （1）提出双流网络。

   （2）即使只有少量的样本，直接在光流上训练的模型也能得到很好的效果。

   （3）提出了一种多任务（multi-task）学习方法可以在两个不同数据集上同时训练。

## 一、Introduction部分

1. 视频数据的优势：

   （1）携带有时间信息，可作为重要线索。

   （2）天生的数据增强：帧之间形变、遮挡、光照改变。

2. 为什么选择人类动作识别：

   （1）与人的行为相关，可以对机器人、VR、AR等有指导意义。

   （2）人类行为的视频网上多，易于收集。

3. 算法构建：两条流。

   （1）空间流：输入为图片，可以使用ImageNet预训练的模型作初始化。

   （2）时间流：输入为光流轨迹，运动信息不用CNN自己学习得到，对分类器的压力小。

4. 玄学：人的视觉也是两条通路：腹侧流（ventral stream）用于物体识别，背侧流（dorsal stream）用于运动识别，尽管没有证据表明这与双流网络有联系。。。

## 二、相关工作部分

1. 图像兴趣点的sift特征演变成视频分析的STIP特征，进而演变为密集轨迹特征dense point trajectories。在进行全局运动信息、Fisher编码后就演变为IDT（2013ICCV）。
2. 2014CVPR：DeepVideo，连续帧作为输入，没有显式的运动信息对分类器挑战大。经过实验，以连续帧作为输入的DeepVideo与以单帧作为输入的2D CNN的分类效果相差不大，进一步证明其没有充分利用时间信息。

## 三、网络总体结构

1. 总体架构：时间流+空间流+late fusion（logits层面上的融合，可以直接加权平均，也可以用得到的L2标准化的softmax分数训练一个 SVM）。
2. 空间流：分析与物体密切相关的运动，类AlexNet的架构，5层conv，2层fc，1层softmax。输入为3通道RGB帧。

## 四、光流

1. 光流求解：对于每一帧图像，取自身与下一帧在能量最小化框架下求解位移场得到光流轨迹，分解为水平分量和竖直分量两张图，于是L帧图像会计算得到2L帧光流。

2. 光流堆叠：一帧图像得到的运动信息有限，直接像RGB一样当成2通道输入没有太大意义，于是采用“光流叠加”，将多张光流叠加在一起。具体方案包含：

   （1）直接叠加：对于L帧图像计算出的2L帧光流，每一帧都看（x,y）这个点下一帧往哪里走了。操作简单，但可能不能充分利用信息。

   （2）按轨迹叠加：2L帧光流中，第一帧的p1点运动到了第二帧的p2点，第二帧的p2点运动到了第三帧的p3点。听起来靠谱很多，充分利用了光流。

   但在本文实验中第一种方法的结果较优，作者也不知道为啥，在总结中说接下来继续研究。

3. 双向光流：L帧图像的前L/2帧做前向光流，后L/2帧做反向光流。

## 五、结果部分（略）

（先是一系列消融实验，找到了最优的训练方法和光流提取方法，接着与其它分类器在UCF101和HMDB51上的结果进行对比，结果基本与IDT打平。）

## 六、Conclusion部分

1. 双流网络虽然增加了时间流，但结构并不复杂。时间流只是将空间流的RGB通道为3改为深度为2L。
2. 双流网络的痛点：需要计算光流，耗时且占空间。
3. 对于基于轨迹叠加的方法提出疑问，最终在2015年（来年）CVPR上被王利民老师的trajectory-pooled features解决，准确率提升到90%+。
4. 关于相机抖动引起的全局噪声：采用全局均值相减的方法消除这一影响。